# Testing Guide - scVAE-Annotator

## ğŸ¯ Test Strategy

This project follows a strict testing philosophy:
- **90%+ coverage** as the minimum goal for production code
- **mypy strict mode** with 100% type safety
- **pytest** as the primary test framework
- **Comprehensive testing**: Unit â†’ Integration â†’ End-to-End

## ğŸ“Š Current Status

| Module | Coverage | Tests | Status |
|--------|----------|-------|--------|
| config.py | 97.78% | 14 âœ… | EXCELLENT |
| vae.py | 100% | 17 âœ… | PERFECT |
| preprocessing.py | 81% | 19 (mixed) | GOOD |
| clustering.py | 41.82% | 8 (mixed) | NEEDS_WORK |
| annotator.py | 11.88% | 0 | CRITICAL |
| pipeline.py | 9.18% | 0 | CRITICAL |
| visualization.py | 14.63% | 0 | CRITICAL |
| cli.py | 0% | 0 | CRITICAL |
| **TOTAL** | **31.10%** | 30 âœ… / 19 âŒ | IN_PROGRESS |

## ğŸš€ Quick Start

### Install test dependencies

```bash
pip install pytest pytest-cov pytest-mock mypy
```

### Run tests

```bash
# All tests
pytest tests/ -v

# With coverage report
pytest tests/ --cov=src/scvae_annotator --cov-report=html --cov-report=term

# Only passing tests
pytest tests/test_config.py tests/test_vae.py -v

# Test a specific module
pytest tests/test_config.py -v --tb=short
```

### Type checking

```bash
# Entire project
mypy src/scvae_annotator

# Single module
mypy src/scvae_annotator/config.py
```

## ğŸ“ Test Structure

### Fully implemented

#### 1. **test_config.py** (14 tests, 97.78% coverage)
```python
# Covered:
âœ… Config dataclass validation
âœ… Parameter constraints (batch_size, epochs, etc.)
âœ… Random seed handling
âœ… create_optimized_config() factory
âœ… Edge cases (zero values, negative numbers)
âœ… Type safety (int/float conversions)
```

**Example:**
```python
def test_config_creation():
    config = Config(
        batch_size=128,
        max_epochs=100,
        learning_rate=0.001
    )
    assert config.batch_size == 128
    assert config.max_epochs == 100
```

#### 2. **test_vae.py** (17 tests, 100% coverage)
```python
# Covered:
âœ… EarlyStopping logic (patience, delta)
âœ… ImprovedVAE forward/loss
âœ… train_improved_vae() with different configs
âœ… CUDA handling (automatic fallback to CPU)
âœ… Loss computation and convergence
âœ… Edge cases (empty training, single batch)
```

**Example:**
```python
def test_vae_training():
    adata = create_test_adata(n_obs=100, n_vars=50)
    trained_vae, losses = train_improved_vae(adata, config)
    assert len(losses) > 0
    assert all(loss >= 0 for loss in losses)
```

### Partially implemented

#### 3. **test_preprocessing.py** (19 tests, 81% coverage)
```python
# Covered:
âœ… enhanced_preprocessing() basics
âœ… discover_marker_genes()
âš ï¸ QC filtering often yields empty data
âš ï¸ Test fixtures need realistic metrics
```

**Issues:**
- Synthetic data does not survive QC filters
- `n_genes_by_counts` and `pct_counts_mt` are often missing
- Recommendation: more robust fixture generation

#### 4. **test_clustering.py** (8 tests, 41.82% coverage)
```python
# Covered:
âœ… optimized_leiden_clustering() basics
âš ï¸ Missing: PCA/neighbors setup in fixtures
âš ï¸ Missing: ARI/Silhouette metrics
```

**Issues:**
- Test data lacks `.obsm['X_pca']`
- Clustering fails without a neighbors graph
- Recommendation: run `sc.pp.neighbors()` in fixtures

### Not yet implemented

#### 5. **test_annotator.py** (0% coverage - CRITICAL)
```python
# Needed:
âŒ EnhancedAutoencoderAnnotator.__init__()
âŒ train() with Optuna optimization
âŒ predict() with confidence scores
âŒ SMOTE handling for imbalanced data
âŒ Calibration (Platt scaling)
âŒ Edge cases (unknown labels, single class)
```

**Priority:** HIGH - Core functionality

#### 6. **test_pipeline.py** (0% coverage - CRITICAL)
```python
# Needed:
âŒ run_annotation_pipeline() end-to-end
âŒ evaluate_predictions() metrics
âŒ analyze_optimization_results()
âŒ save_results() file handling
âŒ Integration: preprocessing â†’ clustering â†’ VAE â†’ annotator
```

**Priority:** HIGH - Orchestration

#### 7. **test_visualization.py** (0% coverage)
```python
# Needed:
âŒ create_visualizations() plot generation
âŒ UMAP consistency
âŒ Confidence plots
âŒ File saving (PNG/PDF)
```

**Priority:** MEDIUM - Output

#### 8. **test_cli.py** (0% coverage)
```python
# Needed:
âŒ main() argument parsing
âŒ Command execution (--help, --version)
âŒ File path validation
âŒ Error handling
```

**Priority:** MEDIUM - User Interface

## ğŸ”§ Test Fixtures Best Practices

### Robust AnnData generation

```python
@pytest.fixture
def realistic_adata():
    """Create AnnData with realistic QC metrics."""
    n_obs, n_vars = 200, 100
    X = np.random.negative_binomial(5, 0.3, (n_obs, n_vars))
    
    adata = ad.AnnData(
        X=X.astype(np.float32),
        obs=pd.DataFrame({
            'n_genes_by_counts': np.random.randint(50, 500, n_obs),
            'total_counts': X.sum(axis=1),
            'pct_counts_mt': np.random.uniform(0, 15, n_obs),
            'cell_type': np.random.choice(['A', 'B', 'C'], n_obs)
        }, index=[f'cell_{i}' for i in range(n_obs)]),
        var=pd.DataFrame({
            'gene_ids': [f'GENE_{i}' for i in range(n_vars)],
            'n_cells_by_counts': np.random.randint(10, n_obs, n_vars),
            'highly_variable': np.random.choice([True, False], n_vars)
        }, index=[f'gene_{i}' for i in range(n_vars)])
    )
    
    # Preprocessing for tests
    sc.pp.normalize_total(adata, target_sum=1e4)
    sc.pp.log1p(adata)
    sc.pp.pca(adata, n_comps=min(30, n_obs - 1, n_vars - 1))
    sc.pp.neighbors(adata)
    
    return adata
```

## ğŸ“ˆ Roadmap to 90%+ Coverage

### Phase 1: Critical modules (Week 1)
```
âœ… config.py (97.78%)
âœ… vae.py (100%)
ğŸ”„ annotator.py (11.88% â†’ 90%+)
ğŸ”„ pipeline.py (9.18% â†’ 90%+)
```

### Phase 2: Integration (Week 2)
```
ğŸ”„ preprocessing.py (81% â†’ 90%+)
ğŸ”„ clustering.py (41.82% â†’ 90%+)
ğŸ”„ visualization.py (14.63% â†’ 90%+)
```

### Phase 3: User Interface (Week 3)
```
ğŸ”„ cli.py (0% â†’ 90%+)
ğŸ“ Integration tests
ğŸ“ End-to-end tests
```

### Phase 4: Polish (Week 4)
```
ğŸ“ Performance tests
ğŸ“ Edge case hardening
ğŸ“ Documentation updates
ğŸ‰ 90%+ coverage reached!
```

## ğŸ› ï¸ Debugging failed tests

### Problem: "Empty data after filtering"

```python
# Root cause
def test_preprocessing():
    adata = ad.AnnData(X=np.random.rand(100, 50))  # âŒ Too simple
    result = enhanced_preprocessing(adata)  # Filters everything out!

# Fix
def test_preprocessing():
    adata = create_realistic_adata()  # âœ… With QC metrics
    result = enhanced_preprocessing(adata)
```

### Problem: "KeyError: 'X_pca'"

```python
# Root cause
def test_clustering():
    adata = ad.AnnData(X=np.random.rand(100, 50))
    optimized_leiden_clustering(adata)  # âŒ No PCA

# Fix
def test_clustering():
    adata = create_realistic_adata()  # âœ… With PCA/neighbors
    optimized_leiden_clustering(adata)
```

## ğŸ“Š Generate a coverage report

```bash
# Terminal report
pytest --cov=src/scvae_annotator --cov-report=term-missing

# HTML report (recommended!)
pytest --cov=src/scvae_annotator --cov-report=html
# Open: htmlcov/index.html

# XML for CI/CD
pytest --cov=src/scvae_annotator --cov-report=xml
```

## ğŸ¯ CI/CD Integration

### GitHub Actions workflow (planned)

```yaml
name: Tests

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: '3.8'
      
      - name: Install dependencies
        run: |
          pip install -e .[dev]
      
      - name: Type checking
        run: mypy src/scvae_annotator
      
      - name: Run tests
        run: pytest --cov --cov-fail-under=90
      
      - name: Upload coverage
        uses: codecov/codecov-action@v3
```

## ğŸ“š Additional resources

- [pytest Documentation](https://docs.pytest.org/)
- [pytest-cov Plugin](https://pytest-cov.readthedocs.io/)
- [mypy Documentation](https://mypy.readthedocs.io/)
- [scanpy Testing Guide](https://scanpy.readthedocs.io/en/stable/dev/testing.html)

---

**Current:** 31.10% coverage | **Target:** 90%+ | **Status:** ğŸš§ In Progress
